"""
æ•°æ®æ‰“åŒ…è„šæœ¬ - å°†æŠ“å–çš„Redditæ•°æ®æ‰“åŒ…æˆå¤§æ¨¡å‹å¯å¤„ç†çš„æ–‡ä»¶
æ”¯æŒæŒ‰æŠ“å–ä¼šè¯ã€æ—¶é—´èŒƒå›´ã€å­ç‰ˆå—ç­‰æ¡ä»¶è¿›è¡Œæ•°æ®æ‰“åŒ…
"""
import argparse
import sys
from datetime import datetime, timedelta
from pathlib import Path
import logging
from typing import List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from database import DatabaseManager
from llm_analyzer import LLMAnalyzer
from data_organizer import DataOrganizer
from config import Config

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('data_packaging.log', encoding='utf-8')
        ]
    )

def main():
    """ä¸»å‡½æ•°"""
    setup_logging()
    logger = logging.getLogger(__name__)
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='Redditæ•°æ®æ‰“åŒ…å·¥å…·')
    parser.add_argument('--start-date', type=str, help='å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--end-date', type=str, help='ç»“æŸæ—¥æœŸ (YYYY-MM-DD)')
    parser.add_argument('--subreddits', type=str, nargs='+', help='å­ç‰ˆå—åˆ—è¡¨')
    parser.add_argument('--format', type=str, choices=['json', 'txt', 'markdown'], 
                       default='json', help='è¾“å‡ºæ ¼å¼')
    parser.add_argument('--output-dir', type=str, default='output', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--include-metadata', action='store_true', 
                       help='åŒ…å«å…ƒæ•°æ®')
    parser.add_argument('--use-llm', action='store_true', 
                       help='ä½¿ç”¨LLMç”Ÿæˆç²¾å‡†å†…å®¹æ¢—æ¦‚')
    parser.add_argument('--llm-provider', type=str, 
                       choices=['openai', 'anthropic', 'deepseek'], 
                       default='openai', help='LLMæä¾›å•†')
    
    args = parser.parse_args()
    
    try:
        # åˆå§‹åŒ–ç»„ä»¶
        logger.info("åˆå§‹åŒ–æ•°æ®åº“å’ŒLLMåˆ†æå™¨...")
        db_manager = DatabaseManager()
        
        llm_analyzer = None
        if args.use_llm:
            try:
                llm_analyzer = LLMAnalyzer()
                logger.info("LLMåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"LLMåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                logger.info("å°†ä½¿ç”¨ç®€å•æ‘˜è¦æ–¹æ³•")
        
        # åˆ›å»ºæ•°æ®æ•´ç†å™¨
        organizer = DataOrganizer(db_manager, llm_analyzer)
        
        # æ•´ç†æ•°æ®
        logger.info("å¼€å§‹æ•´ç†æ•°æ®...")
        organized_data = organizer.organize_data_by_scraping_session(
            start_date=args.start_date,
            end_date=args.end_date,
            subreddits=args.subreddits
        )
        
        if "error" in organized_data:
            logger.error(f"æ•°æ®æ•´ç†å¤±è´¥: {organized_data['error']}")
            return 1
        
        # åˆ›å»ºæ•°æ®åŒ…
        logger.info(f"åˆ›å»º{args.format.upper()}æ ¼å¼æ•°æ®åŒ…...")
        package_content = organizer.create_llm_ready_package(
            organized_data,
            output_format=args.format,
            include_metadata=args.include_metadata
        )
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"reddit_data_{timestamp}.{args.format}"
        
        # ä¿å­˜æ–‡ä»¶
        logger.info(f"ä¿å­˜æ•°æ®åŒ…åˆ° {args.output_dir}/{filename}...")
        file_path = organizer.save_package_to_file(
            package_content,
            filename,
            args.output_dir
        )
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        metadata = organized_data.get('metadata', {})
        logger.info("=" * 60)
        logger.info("æ•°æ®æ‰“åŒ…å®Œæˆ!")
        logger.info(f"æ–‡ä»¶è·¯å¾„: {file_path}")
        logger.info(f"æ€»åˆ†ç»„æ•°: {metadata.get('total_groups', 0)}")
        logger.info(f"æ€»å¸–å­æ•°: {metadata.get('total_posts', 0)}")
        logger.info(f"æ€»è¯„è®ºæ•°: {metadata.get('total_comments', 0)}")
        logger.info(f"æ¶‰åŠå­ç‰ˆå—: {', '.join(metadata.get('subreddits', []))}")
        logger.info("=" * 60)
        
        return 0
        
    except Exception as e:
        logger.error(f"æ•°æ®æ‰“åŒ…å¤±è´¥: {str(e)}")
        return 1

def interactive_mode():
    """äº¤äº’å¼æ¨¡å¼"""
    setup_logging()
    logger = logging.getLogger(__name__)
    
    print("=" * 60)
    print("Redditæ•°æ®æ‰“åŒ…å·¥å…· - äº¤äº’å¼æ¨¡å¼")
    print("=" * 60)
    
    try:
        # åˆå§‹åŒ–ç»„ä»¶
        print("åˆå§‹åŒ–æ•°æ®åº“...")
        db_manager = DatabaseManager()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        stats = db_manager.get_analysis_statistics()
        if stats.get('total_posts', 0) == 0:
            print("âŒ æ•°æ®åº“ä¸­æ²¡æœ‰å¸–å­æ•°æ®ï¼Œè¯·å…ˆè¿›è¡Œæ•°æ®æŠ“å–")
            return 1
        
        print(f"âœ… æ•°æ®åº“ä¸­æœ‰ {stats.get('total_posts', 0)} ä¸ªå¸–å­")
        
        # è·å–å¯ç”¨çš„å­ç‰ˆå—
        subreddits = db_manager.get_subreddit_list()
        print(f"ğŸ“‹ å¯ç”¨çš„å­ç‰ˆå—: {', '.join(subreddits)}")
        
        # ç”¨æˆ·è¾“å…¥
        print("\nè¯·é€‰æ‹©æ•°æ®èŒƒå›´:")
        
        # æ—¥æœŸèŒƒå›´
        start_date = input("å¼€å§‹æ—¥æœŸ (YYYY-MM-DDï¼Œç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶): ").strip()
        if start_date and not _validate_date(start_date):
            print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            start_date = None
        
        end_date = input("ç»“æŸæ—¥æœŸ (YYYY-MM-DDï¼Œç•™ç©ºè¡¨ç¤ºä¸é™åˆ¶): ").strip()
        if end_date and not _validate_date(end_date):
            print("âŒ æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            end_date = None
        
        # å­ç‰ˆå—é€‰æ‹©
        print(f"\nå¯ç”¨çš„å­ç‰ˆå—: {', '.join(subreddits)}")
        subreddit_input = input("é€‰æ‹©å­ç‰ˆå— (ç”¨ç©ºæ ¼åˆ†éš”ï¼Œç•™ç©ºè¡¨ç¤ºå…¨éƒ¨): ").strip()
        selected_subreddits = subreddit_input.split() if subreddit_input else None
        
        # è¾“å‡ºæ ¼å¼
        print("\nè¾“å‡ºæ ¼å¼:")
        print("1. JSON (æ¨è)")
        print("2. TXT")
        print("3. Markdown")
        format_choice = input("é€‰æ‹©æ ¼å¼ (1-3ï¼Œé»˜è®¤1): ").strip()
        format_map = {'1': 'json', '2': 'txt', '3': 'markdown'}
        output_format = format_map.get(format_choice, 'json')
        
        # æ˜¯å¦åŒ…å«å…ƒæ•°æ®
        include_meta = input("åŒ…å«å…ƒæ•°æ®? (y/N): ").strip().lower() == 'y'
        
        # æ˜¯å¦ä½¿ç”¨LLM
        use_llm = input("ä½¿ç”¨LLMç”Ÿæˆç²¾å‡†æ¢—æ¦‚? (y/N): ").strip().lower() == 'y'
        
        # åˆå§‹åŒ–LLMåˆ†æå™¨
        llm_analyzer = None
        if use_llm:
            try:
                llm_analyzer = LLMAnalyzer()
                print("âœ… LLMåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                print(f"âš ï¸ LLMåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                print("å°†ä½¿ç”¨ç®€å•æ‘˜è¦æ–¹æ³•")
        
        # åˆ›å»ºæ•°æ®æ•´ç†å™¨
        organizer = DataOrganizer(db_manager, llm_analyzer)
        
        # æ•´ç†æ•°æ®
        print("\nå¼€å§‹æ•´ç†æ•°æ®...")
        organized_data = organizer.organize_data_by_scraping_session(
            start_date=start_date,
            end_date=end_date,
            subreddits=selected_subreddits
        )
        
        if "error" in organized_data:
            print(f"âŒ æ•°æ®æ•´ç†å¤±è´¥: {organized_data['error']}")
            return 1
        
        # åˆ›å»ºæ•°æ®åŒ…
        print(f"åˆ›å»º{output_format.upper()}æ ¼å¼æ•°æ®åŒ…...")
        package_content = organizer.create_llm_ready_package(
            organized_data,
            output_format=output_format,
            include_metadata=include_meta
        )
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"reddit_data_{timestamp}.{output_format}"
        
        # ä¿å­˜æ–‡ä»¶
        print(f"ä¿å­˜æ•°æ®åŒ…åˆ° output/{filename}...")
        file_path = organizer.save_package_to_file(
            package_content,
            filename,
            "output"
        )
        
        # æ˜¾ç¤ºç»“æœ
        metadata = organized_data.get('metadata', {})
        print("\n" + "=" * 60)
        print("âœ… æ•°æ®æ‰“åŒ…å®Œæˆ!")
        print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {file_path}")
        print(f"ğŸ“Š æ€»åˆ†ç»„æ•°: {metadata.get('total_groups', 0)}")
        print(f"ğŸ“ æ€»å¸–å­æ•°: {metadata.get('total_posts', 0)}")
        print(f"ğŸ’¬ æ€»è¯„è®ºæ•°: {metadata.get('total_comments', 0)}")
        print(f"ğŸ“ æ¶‰åŠå­ç‰ˆå—: {', '.join(metadata.get('subreddits', []))}")
        print("=" * 60)
        
        return 0
        
    except KeyboardInterrupt:
        print("\n\nâŒ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
        return 1
    except Exception as e:
        print(f"\nâŒ æ•°æ®æ‰“åŒ…å¤±è´¥: {str(e)}")
        return 1

def _validate_date(date_string: str) -> bool:
    """éªŒè¯æ—¥æœŸæ ¼å¼"""
    try:
        datetime.strptime(date_string, '%Y-%m-%d')
        return True
    except ValueError:
        return False

if __name__ == "__main__":
    if len(sys.argv) == 1:
        # æ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œè¿›å…¥äº¤äº’å¼æ¨¡å¼
        sys.exit(interactive_mode())
    else:
        # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
        sys.exit(main())
